{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x230ee049f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [-0.00070549]\n",
      "[0 1] [ 0.99517753]\n",
      "[1 0] [ 0.99604615]\n",
      "[1 1] [-0.00023941]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "            \n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "        plt.plot(error)\n",
    "        plt.show()\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
